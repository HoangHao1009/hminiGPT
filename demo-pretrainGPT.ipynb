{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18628,"status":"ok","timestamp":1706493692641,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"},"user_tz":-420},"id":"39EpTw1eNw0p","outputId":"001c10a9-a568-460e-8b36-134706f25c13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'hminiGPT'...\n","remote: Enumerating objects: 121, done.\u001b[K\n","remote: Counting objects: 100% (121/121), done.\u001b[K\n","remote: Compressing objects: 100% (119/119), done.\u001b[K\n","remote: Total 121 (delta 28), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (121/121), 38.72 KiB | 1.43 MiB/s, done.\n","Resolving deltas: 100% (28/28), done.\n","/content/hminiGPT\n","Obtaining file:///content/hminiGPT\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from hhhGPT==0.2) (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->hhhGPT==0.2) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->hhhGPT==0.2) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->hhhGPT==0.2) (1.3.0)\n","Installing collected packages: hhhGPT\n","  Running setup.py develop for hhhGPT\n","Successfully installed hhhGPT-0.2\n"]}],"source":["!git clone https://github.com/HoangHao1009/hminiGPT\n","%cd hminiGPT\n","!pip install -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39056,"status":"ok","timestamp":1706493731693,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"},"user_tz":-420},"id":"_XmqRz6XOR19","outputId":"545a3ce1-ad72-4d22-9357-f99512d7f73a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting https://gitlab.com/trungtv/vi_spacy/-/raw/master/packages/vi_core_news_lg-3.6.0/dist/vi_core_news_lg-3.6.0.tar.gz\n","  Downloading https://gitlab.com/trungtv/vi_spacy/-/raw/master/packages/vi_core_news_lg-3.6.0/dist/vi_core_news_lg-3.6.0.tar.gz (233.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from vi-core-news-lg==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (0.11.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (1.10.14)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (3.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (3.3.0)\n","Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (0.1.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->vi-core-news-lg==3.6.0) (2.1.4)\n","Building wheels for collected packages: vi-core-news-lg\n","  Building wheel for vi-core-news-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vi-core-news-lg: filename=vi_core_news_lg-3.6.0-py3-none-any.whl size=233275663 sha256=a07c519463e40242ecc8c52f6f6d4271347e8a29f07604e06baf4cd95540e371\n","  Stored in directory: /root/.cache/pip/wheels/bd/c2/22/8dfcbf9006c1be9c5f38dda2e8608eddb2f46c933f174c7581\n","Successfully built vi-core-news-lg\n","Installing collected packages: vi-core-news-lg\n","Successfully installed vi-core-news-lg-3.6.0\n"]}],"source":["pip install https://gitlab.com/trungtv/vi_spacy/-/raw/master/packages/vi_core_news_lg-3.6.0/dist/vi_core_news_lg-3.6.0.tar.gz\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9940,"status":"ok","timestamp":1706493741627,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"},"user_tz":-420},"id":"liGZIj5_O0e0","outputId":"6c9ec74e-c0b9-4719-b774-1e49ce9415cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n","Collecting sklearn-crfsuite (from pyvi)\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.2.0)\n","Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.1)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"]}],"source":["pip install pyvi\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_303pM2O2pH"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from torch.optim import lr_scheduler\n","import spacy\n","from hGPT.datacreator import DataCreator, Vocabulary, CustomDataset\n","from hGPT.model import MiniGPT, Trainer, WordVector"]},{"cell_type":"code","source":["CUDA_LAUNCH_BLOCKING=1\n","torch.cuda.synchronize()"],"metadata":{"id":"HTb_Xx9T8sBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"roH8fJd-PFpu","executionInfo":{"status":"ok","timestamp":1706494622495,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93bf1751-c460-4791-9577-e5eeaf1935c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","#model params\n","block_size = 128\n","batch_size = 32\n","vocab_size = None\n","n_emb = 512\n","num_head = 2\n","n_layer = 2\n","dropout = 0.3\n","#trainer params\n","learning_rate = 0.0001\n","eval_iters = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49OYhQ9WPekK","executionInfo":{"status":"ok","timestamp":1706493952066,"user_tz":-420,"elapsed":195357,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"b7b1151d-fd80-4427-fd40-83f7ef1536e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Reading CSV: 250000rows [02:42, 1534.48rows/s]\n","Reading CSV: 50000rows [00:30, 1631.05rows/s]\n"]}],"source":["tokenizer = spacy.load('vi_core_news_lg')\n","train_data = DataCreator(block_size, tokenizer)\n","val_data = DataCreator(block_size, tokenizer)\n","\n","#extractPairs Data:\n","#train_file_path = '/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/10000book_train.txt'\n","#val_file_path = '/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/10000book_val.txt'\n","#train_data.extractPairs(train_file_path, 50000)\n","#val_data.extractPairs(val_file_path, 5000)\n","#train_data.csvwrite('/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/trainGPTdata.csv', ',')\n","#val_data.csvwrite('/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/valGPTdata.csv', ',')\n","\n","#If you've extracted:\n","train_data.csvread('/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/10000book/trainGPTdata.csv', ',')\n","val_data.csvread('/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/10000book/valGPTdata.csv', ',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWaloo9lQUP3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706494021456,"user_tz":-420,"elapsed":69402,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"4a97905f-d571-4986-9303-b577fab172d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Keep 60644 in total 165469 = 36.649765%\n"]}],"source":["voc = Vocabulary()\n","train_dataset = CustomDataset(train_data.pairs, voc, device, min_count = 5, type = 'train')\n","val_dataset = CustomDataset(val_data.pairs, voc, device, type = 'val')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5edbDGDQ6go"},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size, shuffle = True)\n","val_dataloader = DataLoader(val_dataset, batch_size, shuffle = True)"]},{"cell_type":"code","source":["model = MiniGPT(voc.num_words, n_emb, block_size, num_head, n_layer, dropout, device)\n","m = model.to(device)"],"metadata":{"id":"sZ7IN-z_i4Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.cuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0fgOgGG7wrH","executionInfo":{"status":"ok","timestamp":1706494631052,"user_tz":-420,"elapsed":2,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"cc52a7c0-499d-4e81-e77c-59c0aea9b10b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.cuda of MiniGPT(\n","  (token_embedding): Embedding(60646, 512)\n","  (position_embedding): Embedding(128, 512)\n","  (trans_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (self_attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-1): 2 x HeadAttention(\n","            (key): Linear(in_features=512, out_features=256, bias=False)\n","            (query): Linear(in_features=512, out_features=256, bias=False)\n","            (value): Linear(in_features=512, out_features=256, bias=False)\n","            (dropout): Dropout(p=0.3, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","      )\n","      (feedforward): Sequential(\n","        (0): Linear(in_features=512, out_features=2048, bias=True)\n","        (1): ReLU()\n","        (2): Linear(in_features=2048, out_features=512, bias=True)\n","        (3): Dropout(p=0.3, inplace=False)\n","      )\n","      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): TransformerBlock(\n","      (self_attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-1): 2 x HeadAttention(\n","            (key): Linear(in_features=512, out_features=256, bias=False)\n","            (query): Linear(in_features=512, out_features=256, bias=False)\n","            (value): Linear(in_features=512, out_features=256, bias=False)\n","            (dropout): Dropout(p=0.3, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.3, inplace=False)\n","      )\n","      (feedforward): Sequential(\n","        (0): Linear(in_features=512, out_features=2048, bias=True)\n","        (1): ReLU()\n","        (2): Linear(in_features=2048, out_features=512, bias=True)\n","        (3): Dropout(p=0.3, inplace=False)\n","      )\n","      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  (lm_head): Linear(in_features=512, out_features=60646, bias=True)\n",")>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"],"metadata":{"id":"7I6l6bBiwmFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(train_dataloader, val_dataloader, model, optimizer, eval_iters)\n","trainer.start_training(1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hT-IgHIYxHPL","executionInfo":{"status":"ok","timestamp":1706495412077,"user_tz":-420,"elapsed":774418,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"0e7c8c4e-dea8-4f64-ae5f-8e5eb26da97a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0: Train loss: 11.106707572937012/ Val loss: 11.106467247009277\n","Step 50: Train loss: 7.73062801361084/ Val loss: 7.720537185668945\n","Step 100: Train loss: 7.1295166015625/ Val loss: 7.110549449920654\n","Step 150: Train loss: 7.048479080200195/ Val loss: 7.0374603271484375\n","Step 200: Train loss: 6.965098857879639/ Val loss: 6.954097270965576\n","Step 250: Train loss: 6.877810001373291/ Val loss: 6.876185417175293\n","Step 300: Train loss: 6.804450035095215/ Val loss: 6.8037848472595215\n","Step 350: Train loss: 6.7003278732299805/ Val loss: 6.718346118927002\n","Step 400: Train loss: 6.641290187835693/ Val loss: 6.643800258636475\n","Step 450: Train loss: 6.564385414123535/ Val loss: 6.553297519683838\n","Step 500: Train loss: 6.525985240936279/ Val loss: 6.504528045654297\n","Step 550: Train loss: 6.4490275382995605/ Val loss: 6.453876972198486\n","Step 600: Train loss: 6.4017558097839355/ Val loss: 6.395174503326416\n","Step 650: Train loss: 6.376269340515137/ Val loss: 6.328586578369141\n","Step 700: Train loss: 6.315573692321777/ Val loss: 6.305622577667236\n","Step 750: Train loss: 6.273520469665527/ Val loss: 6.292652606964111\n","Step 800: Train loss: 6.259787559509277/ Val loss: 6.24392557144165\n","Step 850: Train loss: 6.211350917816162/ Val loss: 6.206478118896484\n","Step 900: Train loss: 6.1836934089660645/ Val loss: 6.1762590408325195\n","Step 950: Train loss: 6.146791934967041/ Val loss: 6.160238742828369\n"]}]},{"cell_type":"code","source":["trainer.start_training(1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQxnQ52i8RkZ","executionInfo":{"status":"ok","timestamp":1706496221499,"user_tz":-420,"elapsed":777395,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"17521c8e-1525-4386-9dfc-e43591a6977f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0: Train loss: 6.131241321563721/ Val loss: 6.134433746337891\n","Step 50: Train loss: 6.117010593414307/ Val loss: 6.0885443687438965\n","Step 100: Train loss: 6.083968639373779/ Val loss: 6.066431999206543\n","Step 150: Train loss: 6.0530619621276855/ Val loss: 6.053677558898926\n","Step 200: Train loss: 6.025522232055664/ Val loss: 6.035211086273193\n","Step 250: Train loss: 6.01740837097168/ Val loss: 6.008098602294922\n","Step 300: Train loss: 6.009273529052734/ Val loss: 6.016934871673584\n","Step 350: Train loss: 5.994997024536133/ Val loss: 5.976059436798096\n","Step 400: Train loss: 5.975733757019043/ Val loss: 5.976858615875244\n","Step 450: Train loss: 5.951131820678711/ Val loss: 5.9807868003845215\n","Step 500: Train loss: 5.933539867401123/ Val loss: 5.942166805267334\n","Step 550: Train loss: 5.914873123168945/ Val loss: 5.928574085235596\n","Step 600: Train loss: 5.906093597412109/ Val loss: 5.931536674499512\n","Step 650: Train loss: 5.884488582611084/ Val loss: 5.90078067779541\n","Step 700: Train loss: 5.885556697845459/ Val loss: 5.902190685272217\n","Step 750: Train loss: 5.868274688720703/ Val loss: 5.885356426239014\n","Step 800: Train loss: 5.8418450355529785/ Val loss: 5.856569766998291\n","Step 850: Train loss: 5.838952541351318/ Val loss: 5.8710198402404785\n","Step 900: Train loss: 5.828141689300537/ Val loss: 5.849483489990234\n","Step 950: Train loss: 5.810294151306152/ Val loss: 5.84044075012207\n"]}]},{"cell_type":"code","source":["trainer.start_training(2000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7RGT_VxDgF1","executionInfo":{"status":"ok","timestamp":1706497806720,"user_tz":-420,"elapsed":1557069,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"43402571-0ae1-42e1-9703-4e0b269a1e3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0: Train loss: 5.813185214996338/ Val loss: 5.821667671203613\n","Step 50: Train loss: 5.780452251434326/ Val loss: 5.822023868560791\n","Step 100: Train loss: 5.784909725189209/ Val loss: 5.823739528656006\n","Step 150: Train loss: 5.767423629760742/ Val loss: 5.803229808807373\n","Step 200: Train loss: 5.767155647277832/ Val loss: 5.795984268188477\n","Step 250: Train loss: 5.73458194732666/ Val loss: 5.7717814445495605\n","Step 300: Train loss: 5.7463459968566895/ Val loss: 5.770205020904541\n","Step 350: Train loss: 5.732873916625977/ Val loss: 5.754355430603027\n","Step 400: Train loss: 5.7281174659729/ Val loss: 5.742471694946289\n","Step 450: Train loss: 5.7178826332092285/ Val loss: 5.741108417510986\n","Step 500: Train loss: 5.683190822601318/ Val loss: 5.743659019470215\n","Step 550: Train loss: 5.687924861907959/ Val loss: 5.739001274108887\n","Step 600: Train loss: 5.665472030639648/ Val loss: 5.72268533706665\n","Step 650: Train loss: 5.6624674797058105/ Val loss: 5.71302604675293\n","Step 700: Train loss: 5.657200813293457/ Val loss: 5.724880218505859\n","Step 750: Train loss: 5.634592056274414/ Val loss: 5.6835808753967285\n","Step 800: Train loss: 5.637087345123291/ Val loss: 5.691767692565918\n","Step 850: Train loss: 5.626928806304932/ Val loss: 5.695946216583252\n","Step 900: Train loss: 5.630839824676514/ Val loss: 5.668889045715332\n","Step 950: Train loss: 5.617401599884033/ Val loss: 5.6848249435424805\n","Step 1000: Train loss: 5.591267108917236/ Val loss: 5.6525492668151855\n","Step 1050: Train loss: 5.60633659362793/ Val loss: 5.650623321533203\n","Step 1100: Train loss: 5.592546463012695/ Val loss: 5.650486469268799\n","Step 1150: Train loss: 5.595526695251465/ Val loss: 5.645349502563477\n","Step 1200: Train loss: 5.566197395324707/ Val loss: 5.6502366065979\n","Step 1250: Train loss: 5.563520431518555/ Val loss: 5.630098819732666\n","Step 1300: Train loss: 5.566497802734375/ Val loss: 5.638312339782715\n","Step 1350: Train loss: 5.55918025970459/ Val loss: 5.632389068603516\n","Step 1400: Train loss: 5.567230701446533/ Val loss: 5.602972030639648\n","Step 1450: Train loss: 5.576596736907959/ Val loss: 5.608942985534668\n","Step 1500: Train loss: 5.525781154632568/ Val loss: 5.602437973022461\n","Step 1550: Train loss: 5.522836685180664/ Val loss: 5.609682559967041\n","Step 1600: Train loss: 5.525129318237305/ Val loss: 5.588503360748291\n","Step 1650: Train loss: 5.520003795623779/ Val loss: 5.583970546722412\n","Step 1700: Train loss: 5.520900726318359/ Val loss: 5.584875583648682\n","Step 1750: Train loss: 5.514229774475098/ Val loss: 5.57888126373291\n","Step 1800: Train loss: 5.499520301818848/ Val loss: 5.569143295288086\n","Step 1850: Train loss: 5.488613128662109/ Val loss: 5.564376354217529\n","Step 1900: Train loss: 5.492380142211914/ Val loss: 5.5577850341796875\n","Step 1950: Train loss: 5.513448715209961/ Val loss: 5.565708637237549\n"]}]},{"cell_type":"code","source":["trainer.start_training(1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8lCMQjLGkwM","executionInfo":{"status":"ok","timestamp":1706498677427,"user_tz":-420,"elapsed":778972,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"55e2aede-5295-413f-fa82-15e11e24d71c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0: Train loss: 5.478590488433838/ Val loss: 5.568547248840332\n","Step 50: Train loss: 5.468776226043701/ Val loss: 5.559711933135986\n","Step 100: Train loss: 5.45071268081665/ Val loss: 5.548589706420898\n","Step 150: Train loss: 5.455460071563721/ Val loss: 5.544882774353027\n","Step 200: Train loss: 5.46367073059082/ Val loss: 5.526522159576416\n","Step 250: Train loss: 5.445815563201904/ Val loss: 5.52263069152832\n","Step 300: Train loss: 5.460038661956787/ Val loss: 5.526165962219238\n","Step 350: Train loss: 5.448351860046387/ Val loss: 5.510110378265381\n","Step 400: Train loss: 5.449069976806641/ Val loss: 5.524076461791992\n","Step 450: Train loss: 5.427732467651367/ Val loss: 5.4994120597839355\n","Step 500: Train loss: 5.43520975112915/ Val loss: 5.518751621246338\n","Step 550: Train loss: 5.439608097076416/ Val loss: 5.512999057769775\n","Step 600: Train loss: 5.435047626495361/ Val loss: 5.509336948394775\n","Step 650: Train loss: 5.434916973114014/ Val loss: 5.507773399353027\n","Step 700: Train loss: 5.41361141204834/ Val loss: 5.4872660636901855\n","Step 750: Train loss: 5.422749042510986/ Val loss: 5.476765155792236\n","Step 800: Train loss: 5.4071946144104/ Val loss: 5.4877142906188965\n","Step 850: Train loss: 5.423816680908203/ Val loss: 5.492661952972412\n","Step 900: Train loss: 5.396691799163818/ Val loss: 5.477372646331787\n","Step 950: Train loss: 5.389716625213623/ Val loss: 5.486124038696289\n"]}]},{"cell_type":"code","source":["trainer.save_model(\n","    voc,\n","    '/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/10000book/saveGPTmodel5000.pt'\n",")"],"metadata":{"id":"ebHKVPYgMwxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.start_training(5000)\n","trainer.save_model(\n","    voc,\n","    '/content/drive/Othercomputers/My Laptop/Personal/hminiGPT/10000book/saveGPTmodel10000.pt'\n",")\n","print('Saving succesfully')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcojZpmAQUYm","executionInfo":{"status":"ok","timestamp":1706502785917,"user_tz":-420,"elapsed":3910787,"user":{"displayName":"Hoàng Hảo","userId":"15415054069727099899"}},"outputId":"4ee82c01-105a-4f75-c8ea-2e60072cb5d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0: Train loss: 5.382081508636475/ Val loss: 5.483151912689209\n","Step 50: Train loss: 5.389092445373535/ Val loss: 5.476998329162598\n","Step 100: Train loss: 5.375117301940918/ Val loss: 5.470396041870117\n","Step 150: Train loss: 5.382370471954346/ Val loss: 5.476761341094971\n","Step 200: Train loss: 5.378304481506348/ Val loss: 5.4546356201171875\n","Step 250: Train loss: 5.357542514801025/ Val loss: 5.460648059844971\n","Step 300: Train loss: 5.360203742980957/ Val loss: 5.45670223236084\n","Step 350: Train loss: 5.3553466796875/ Val loss: 5.462347507476807\n","Step 400: Train loss: 5.360458850860596/ Val loss: 5.459204196929932\n","Step 450: Train loss: 5.35096549987793/ Val loss: 5.454953670501709\n","Step 500: Train loss: 5.343104362487793/ Val loss: 5.445811748504639\n","Step 550: Train loss: 5.354085922241211/ Val loss: 5.443505764007568\n","Step 600: Train loss: 5.334701061248779/ Val loss: 5.4496870040893555\n","Step 650: Train loss: 5.331259727478027/ Val loss: 5.447030067443848\n","Step 700: Train loss: 5.342055797576904/ Val loss: 5.444612503051758\n","Step 750: Train loss: 5.3211822509765625/ Val loss: 5.423241138458252\n","Step 800: Train loss: 5.315328598022461/ Val loss: 5.423274993896484\n","Step 850: Train loss: 5.333447456359863/ Val loss: 5.4345293045043945\n","Step 900: Train loss: 5.3052144050598145/ Val loss: 5.431056976318359\n","Step 950: Train loss: 5.3169169425964355/ Val loss: 5.420174598693848\n","Step 1000: Train loss: 5.296879291534424/ Val loss: 5.416467189788818\n","Step 1050: Train loss: 5.321649074554443/ Val loss: 5.420104503631592\n","Step 1100: Train loss: 5.298407077789307/ Val loss: 5.404840469360352\n","Step 1150: Train loss: 5.295262336730957/ Val loss: 5.401081562042236\n","Step 1200: Train loss: 5.294849872589111/ Val loss: 5.409992218017578\n","Step 1250: Train loss: 5.290494918823242/ Val loss: 5.4236273765563965\n","Step 1300: Train loss: 5.30169677734375/ Val loss: 5.397652626037598\n","Step 1350: Train loss: 5.284451484680176/ Val loss: 5.398525238037109\n","Step 1400: Train loss: 5.293676853179932/ Val loss: 5.416755199432373\n","Step 1450: Train loss: 5.284181118011475/ Val loss: 5.411755561828613\n","Step 1500: Train loss: 5.269237041473389/ Val loss: 5.388149261474609\n","Step 1550: Train loss: 5.288393020629883/ Val loss: 5.389886856079102\n","Step 1600: Train loss: 5.297418594360352/ Val loss: 5.3951287269592285\n","Step 1650: Train loss: 5.279445171356201/ Val loss: 5.400903701782227\n","Step 1700: Train loss: 5.259186267852783/ Val loss: 5.391549110412598\n","Step 1750: Train loss: 5.284059047698975/ Val loss: 5.377327919006348\n","Step 1800: Train loss: 5.268369674682617/ Val loss: 5.383448600769043\n","Step 1850: Train loss: 5.253215312957764/ Val loss: 5.386860370635986\n","Step 1900: Train loss: 5.264912128448486/ Val loss: 5.379483699798584\n","Step 1950: Train loss: 5.2483744621276855/ Val loss: 5.3825507164001465\n","Step 2000: Train loss: 5.252338886260986/ Val loss: 5.367605686187744\n","Step 2050: Train loss: 5.244318008422852/ Val loss: 5.370659828186035\n","Step 2100: Train loss: 5.248025894165039/ Val loss: 5.3812479972839355\n","Step 2150: Train loss: 5.234743595123291/ Val loss: 5.377491474151611\n","Step 2200: Train loss: 5.248726844787598/ Val loss: 5.3742899894714355\n","Step 2250: Train loss: 5.231363296508789/ Val loss: 5.376327037811279\n","Step 2300: Train loss: 5.249915599822998/ Val loss: 5.380423069000244\n","Step 2350: Train loss: 5.237401008605957/ Val loss: 5.368399620056152\n","Step 2400: Train loss: 5.242228984832764/ Val loss: 5.3682541847229\n","Step 2450: Train loss: 5.221160888671875/ Val loss: 5.352369785308838\n","Step 2500: Train loss: 5.233741283416748/ Val loss: 5.362234592437744\n","Step 2550: Train loss: 5.198566913604736/ Val loss: 5.350414276123047\n","Step 2600: Train loss: 5.217288017272949/ Val loss: 5.346572399139404\n","Step 2650: Train loss: 5.223536491394043/ Val loss: 5.351285934448242\n","Step 2700: Train loss: 5.1978912353515625/ Val loss: 5.345991134643555\n","Step 2750: Train loss: 5.226856231689453/ Val loss: 5.336491584777832\n","Step 2800: Train loss: 5.216142654418945/ Val loss: 5.349033355712891\n","Step 2850: Train loss: 5.213879585266113/ Val loss: 5.339547157287598\n","Step 2900: Train loss: 5.2290167808532715/ Val loss: 5.3408284187316895\n","Step 2950: Train loss: 5.1872758865356445/ Val loss: 5.356602668762207\n","Step 3000: Train loss: 5.2108235359191895/ Val loss: 5.359605312347412\n","Step 3050: Train loss: 5.1927170753479/ Val loss: 5.32797384262085\n","Step 3100: Train loss: 5.176627159118652/ Val loss: 5.339806079864502\n","Step 3150: Train loss: 5.1946635246276855/ Val loss: 5.319805145263672\n","Step 3200: Train loss: 5.194890022277832/ Val loss: 5.346381664276123\n","Step 3250: Train loss: 5.187906265258789/ Val loss: 5.339405536651611\n","Step 3300: Train loss: 5.19130802154541/ Val loss: 5.328097343444824\n","Step 3350: Train loss: 5.187136650085449/ Val loss: 5.318986415863037\n","Step 3400: Train loss: 5.181860446929932/ Val loss: 5.336108207702637\n","Step 3450: Train loss: 5.1744866371154785/ Val loss: 5.3210039138793945\n","Step 3500: Train loss: 5.187952041625977/ Val loss: 5.33127498626709\n","Step 3550: Train loss: 5.181113243103027/ Val loss: 5.323946475982666\n","Step 3600: Train loss: 5.149404525756836/ Val loss: 5.317788124084473\n","Step 3650: Train loss: 5.156816482543945/ Val loss: 5.311829090118408\n","Step 3700: Train loss: 5.167585849761963/ Val loss: 5.289257049560547\n","Step 3750: Train loss: 5.1553425788879395/ Val loss: 5.303102016448975\n","Step 3800: Train loss: 5.175907611846924/ Val loss: 5.3223443031311035\n","Step 3850: Train loss: 5.16419792175293/ Val loss: 5.304409027099609\n","Step 3900: Train loss: 5.147562026977539/ Val loss: 5.317191123962402\n","Step 3950: Train loss: 5.171403408050537/ Val loss: 5.308649063110352\n","Step 4000: Train loss: 5.180798530578613/ Val loss: 5.309118747711182\n","Step 4050: Train loss: 5.163985729217529/ Val loss: 5.294571399688721\n","Step 4100: Train loss: 5.162664890289307/ Val loss: 5.301040172576904\n","Step 4150: Train loss: 5.153276443481445/ Val loss: 5.31378173828125\n","Step 4200: Train loss: 5.151402473449707/ Val loss: 5.2943034172058105\n","Step 4250: Train loss: 5.145730495452881/ Val loss: 5.294024467468262\n","Step 4300: Train loss: 5.150447368621826/ Val loss: 5.303966045379639\n","Step 4350: Train loss: 5.154890537261963/ Val loss: 5.302021026611328\n","Step 4400: Train loss: 5.1367645263671875/ Val loss: 5.2926225662231445\n","Step 4450: Train loss: 5.139090061187744/ Val loss: 5.288964748382568\n","Step 4500: Train loss: 5.133600234985352/ Val loss: 5.282709121704102\n","Step 4550: Train loss: 5.113647937774658/ Val loss: 5.28774356842041\n","Step 4600: Train loss: 5.120248317718506/ Val loss: 5.28962516784668\n","Step 4650: Train loss: 5.136917591094971/ Val loss: 5.298843860626221\n","Step 4700: Train loss: 5.132745265960693/ Val loss: 5.296182155609131\n","Step 4750: Train loss: 5.111515998840332/ Val loss: 5.2898993492126465\n","Step 4800: Train loss: 5.113801002502441/ Val loss: 5.2905144691467285\n","Step 4850: Train loss: 5.122311592102051/ Val loss: 5.282036781311035\n","Step 4900: Train loss: 5.136223316192627/ Val loss: 5.299985408782959\n","Step 4950: Train loss: 5.116403579711914/ Val loss: 5.2695698738098145\n","Saving succesfully\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1OOUFBUmKWtbSbvsWXeYCn5m3DGg-bzQ8","authorship_tag":"ABX9TyO+ROXCfgpSQcaMmdUSQlge"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}